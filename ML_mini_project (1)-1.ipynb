{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03a8a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read in data\n",
    "df = pd.read_csv(r\"C:\\Users\\parir\\Downloads\\model.csv\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('default', axis=1)\n",
    "y = df['default']\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106ae91",
   "metadata": {},
   "source": [
    "Uses SimpleImputer from scikit-learn to impute missing values with the median of each column.\n",
    "Uses StandardScaler from scikit-learn to standardize (i.e., scale) the features to have zero mean and unit variance.\n",
    "Uses train_test_split from scikit-learn to split the data into training and validation sets (80% training, 20% validation) to prevent data leakage. The random_state parameter is set to 42 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d7b4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     18051\n",
      "           1       0.43      0.03      0.05       749\n",
      "\n",
      "    accuracy                           0.96     18800\n",
      "   macro avg       0.70      0.51      0.51     18800\n",
      "weighted avg       0.94      0.96      0.94     18800\n",
      "\n",
      "ROC AUC score: 0.8119185227968908\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_preds = logreg.predict(X_val)\n",
    "logreg_proba = logreg.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Print classification report and ROC AUC score\n",
    "print('Logistic Regression:\\n', classification_report(y_val, logreg_preds))\n",
    "print('ROC AUC score:', roc_auc_score(y_val, logreg_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f78a84",
   "metadata": {},
   "source": [
    "Fits a logistic regression model to the training data and makes predictions on the validation data. Calculates the classification report and ROC AUC score to evaluate the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b77902",
   "metadata": {},
   "source": [
    "The AUC score ranges from 0.0 to 1.0, where a score of 0.5 indicates a random classifier and a score of 1.0 indicates a perfect classifier. Higher AUC scores indicate better overall performance of the model in distinguishing between the positive and negative classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fbee784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     18051\n",
      "           1       0.52      0.02      0.03       749\n",
      "\n",
      "    accuracy                           0.96     18800\n",
      "   macro avg       0.74      0.51      0.51     18800\n",
      "weighted avg       0.94      0.96      0.94     18800\n",
      "\n",
      "ROC AUC score: 0.807635116909152\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_val)\n",
    "rf_proba = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Print classification report and ROC AUC score\n",
    "print('Random Forest:\\n', classification_report(y_val, rf_preds))\n",
    "print('ROC AUC score:', roc_auc_score(y_val, rf_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05037db",
   "metadata": {},
   "source": [
    "For logistic regression, I didn't perform any feature engineering as it's a linear model and assumes that the features are linearly related to the target variable. For random forest, I didn't perform any feature selection as random forests are able to handle a large number of features.\n",
    "For both models, I used the default hyperparameters, but you could try tuning the hyperparameters using GridSearchCV or RandomizedSearchCV from scikit-learn to improve the model's performance. Also note that I used the classification report and ROC AUC score to evaluate the model's performance, but there are other metrics you could use depending on the specifics of your problem (e.g., precision, recall, F1 score, accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d4ded",
   "metadata": {},
   "source": [
    "ROC- AUC score provides a single value to summarize the overall model performance and allows for comparison of different models or tuning of model parameters. Thus, we can say Logistic Regression is slighlty a better fit for the training data than Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8618d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv(r\"C:\\Users\\parir\\Downloads\\val.csv\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('default', axis=1)\n",
    "y = df['default']\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef5229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression predictions\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_preds = lr_model.predict_proba(X_val)[:,1] # class probabilities for default class\n",
    "lr_df = pd.DataFrame(lr_preds, columns=['predictions'])\n",
    "lr_df.to_csv('results1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc37a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest predictions\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_preds = rf_model.predict_proba(X_val)[:,1] # class probabilities for default class\n",
    "rf_df = pd.DataFrame(rf_preds, columns=['predictions'])\n",
    "rf_df.to_csv('results2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec57267",
   "metadata": {},
   "source": [
    "This will save the predictions for each model in separate CSV files named results1.csv and results2.csv. The CSV files will have a single column representing the output from each model, and no header label or index column is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fbc336",
   "metadata": {},
   "source": [
    "Logistic Regression:\n",
    "\n",
    "Pros:\n",
    "\n",
    "Simple and easy to interpret.\n",
    "Computationally efficient, even with large datasets.\n",
    "Can handle binary and multi-class classification problems.\n",
    "Can provide class probabilities in addition to binary predictions.\n",
    "\n",
    "Cons:\n",
    "Assumes a linear relationship between features and the target variable.\n",
    "Limited by the assumptions of the underlying statistical model.\n",
    "Can be sensitive to outliers and multicollinearity.\n",
    "May underperform when there are non-linear relationships or interactions between features.\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "Pros:\n",
    "\n",
    "Can capture non-linear relationships and interactions between features.\n",
    "Can handle a mix of categorical and numerical features.\n",
    "Robust to outliers and missing data.\n",
    "Can provide feature importance rankings.\n",
    "Generally perform well on a wide range of problems.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Can be computationally expensive, especially with large datasets and many trees.\n",
    "Can be prone to overfitting if hyperparameters are not tuned correctly.\n",
    "May be less interpretable than simpler models like logistic regression.\n",
    "Can be difficult to diagnose and debug if issues arise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84da6ca",
   "metadata": {},
   "source": [
    "Considerations for business context\n",
    "In a business context, there are several additional factors to consider when choosing a modeling technique:\n",
    "\n",
    "Interpretability: Depending on the problem domain, it may be important to choose a model that is easy to interpret and explain to stakeholders. In this case, logistic regression may be preferred over random forest.\n",
    "\n",
    "Computation time: If the dataset is very large, or if predictions need to be generated in real-time, the computational efficiency of the model may be a critical factor. In this case, logistic regression may be preferred over random forest.\n",
    "\n",
    "Performance metrics: The choice of performance metrics should be aligned with the specific business goal of the model. For example, if the goal is to minimize false positives (i.e. predicting someone will default when they won't), then precision may be a more important metric than recall. It's important to choose a model and tuning strategy that maximizes the desired performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e741268",
   "metadata": {},
   "source": [
    "Overall, both logistic regression and random forest are useful modeling techniques that have their own strengths and weaknesses. The choice of model and tuning strategy should be based on the specific problem domain, available data, and business requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a52fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
